# å¸¸è¦‹å•é¡Œèˆ‡æ•…éšœæ’é™¤æŒ‡å—

## ğŸš€ å•Ÿå‹•èˆ‡éƒ¨ç½²ç›¸é—œ

### Q1: å®¹å™¨ç„¡æ³•å•Ÿå‹•

**ç—‡ç‹€**: `docker-compose up` å¾Œå®¹å™¨ç«‹å³é€€å‡ºæˆ–æŒçºŒé‡å•Ÿ

**è§£æ±ºæ­¥é©Ÿ**:

1. **æŸ¥çœ‹è©³ç´°éŒ¯èª¤è¨Šæ¯**
```bash
docker-compose logs --tail=50
# æˆ–æŸ¥çœ‹ç‰¹å®šæœå‹™
docker-compose logs backend
docker-compose logs crawler-service
```

2. **æ¸…ç†ä¸¦é‡æ–°å»ºç½®**
```bash
docker-compose down -v
docker system prune -a
docker-compose up -d --build
```

3. **æª¢æŸ¥ç£ç¢Ÿç©ºé–“**
```bash
df -h
# å¦‚æœ /var/lib/docker ç©ºé–“ä¸è¶³ï¼ŒåŸ·è¡Œæ¸…ç†
docker image prune -a
docker volume prune
```

4. **é©—è­‰ç’°å¢ƒè®Šæ•¸**
```bash
# æª¢æŸ¥ .env æª”æ¡ˆ
cat .env

# ç¢ºèªè®Šæ•¸æ ¼å¼æ­£ç¢ºï¼ˆç„¡å¼•è™Ÿã€ç„¡ç©ºæ ¼ï¼‰
DATABASE_URL=postgresql://user:password@postgres:5432/stock_analysis
```

### Q2: ç«¯å£è¢«ä½”ç”¨

**ç—‡ç‹€**: `Error response from daemon: driver failed programming external connectivity`

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æ‰¾å‡ºä½”ç”¨ç«¯å£çš„ç¨‹åºï¼ˆä»¥ 3000 ç‚ºä¾‹ï¼‰
lsof -i :3000

# çµ‚æ­¢ç¨‹åº
kill -9 <PID>

# æˆ–ä¿®æ”¹ docker-compose.yml çš„ ports è¨­å®š
# å°‡ "3000:3000" æ”¹ç‚º "3001:3000"
```

### Q3: Docker daemon ä¸é‹è¡Œ

**ç—‡ç‹€**: `Cannot connect to Docker daemon`

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# å•Ÿå‹• Dockerï¼ˆLinuxï¼‰
sudo systemctl start docker

# æˆ–é‡æ–°å•Ÿå‹•ï¼ˆmacOS/Windowsï¼‰
# åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­é–‹å•Ÿ Docker Desktop

# é©—è­‰ Docker é‹è¡Œ
docker --version
docker ps
```

## ğŸ“Š è³‡æ–™åº«ç›¸é—œ

### Q4: è³‡æ–™åº«é€£ç·šå¤±æ•—

**ç—‡ç‹€**: `connection refused` æˆ– `authentication failed`

**æª¢æŸ¥æ¸…å–®**:

1. **é©—è­‰è³‡æ–™åº«å®¹å™¨æ˜¯å¦é‹è¡Œ**
```bash
docker-compose ps postgres

# ç‹€æ…‹æ‡‰ç‚º "Up"
# å¦‚æœªå•Ÿå‹•ï¼š
docker-compose up -d postgres
sleep 10  # ç­‰å¾…åˆå§‹åŒ–
```

2. **æª¢æŸ¥é€£ç·šè¨­å®š**
```bash
# æŸ¥çœ‹ç’°å¢ƒè®Šæ•¸
echo $DATABASE_URL

# é©—è­‰æ­£ç¢ºæ ¼å¼
# postgresql://username:password@host:port/dbname
```

3. **æ¸¬è©¦é€£ç·š**
```bash
# é€²å…¥ postgres å®¹å™¨æ¸¬è©¦é€£ç·š
docker-compose exec postgres psql -U stock_user -d stock_analysis -c "SELECT 1"

# å¾ä¸»æ©Ÿæ¸¬è©¦ï¼ˆéœ€è£ psqlï¼‰
psql postgresql://stock_user:password@localhost:9222/stock_analysis -c "SELECT 1"
```

4. **æŸ¥çœ‹è³‡æ–™åº«æ—¥èªŒ**
```bash
docker-compose logs postgres | tail -50
```

5. **é‡å•Ÿè³‡æ–™åº«**
```bash
docker-compose restart postgres
sleep 15
```

### Q5: è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—

**ç—‡ç‹€**: ç„¡ `stock_daily_data` è¡¨æˆ–å…¶ä»–è¡¨ç¼ºå¤±

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# 1. æª¢æŸ¥é·ç§»ç‹€æ…‹
docker-compose exec backend alembic current

# 2. åŸ·è¡Œé·ç§»
docker-compose exec backend alembic upgrade head

# 3. é©—è­‰è¡¨å­˜åœ¨
docker-compose exec postgres psql -U stock_user -d stock_analysis -c "\dt"

# å¦‚ä»ç„¶å¤±æ•—ï¼ŒåŸ·è¡Œåˆå§‹åŒ– SQL
docker-compose exec -T postgres psql -U stock_user stock_analysis < backend/sql/init.sql
```

### Q6: ç£ç¢Ÿç©ºé–“æ»¿å°è‡´è³‡æ–™åº«æ•…éšœ

**ç—‡ç‹€**: `No space left on device` éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨é‡
df -h

# æŸ¥çœ‹ Docker è³‡æ–™å·å¤§å°
docker system df

# æ¸…ç†èˆŠæ—¥èªŒ
docker-compose exec postgres \
  find /var/log/postgresql -name "*.log" -mtime +30 -delete

# æ¸…ç†å®¹å™¨ç”¢ç”Ÿçš„åƒåœ¾
docker system prune

# æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨è³‡æº
docker system prune -a
```

## ğŸ” çˆ¬èŸ²æœå‹™ç›¸é—œ

### Q7: çˆ¬èŸ²è³‡æ–™å…¨éƒ¨é‡è¤‡

**ç—‡ç‹€**: è‚¡ç¥¨ 2330 æ‰€æœ‰è¨˜éŒ„é¡¯ç¤ºç›¸åŒ open/high/low/close (1665/1700/1655/1680)

**åŸå› **: Go range loop æŒ‡æ¨™åˆ¥å bugï¼ˆå·²æ–¼ 2026-01-11 ä¿®å¾©ï¼‰

**é©—è­‰æ˜¯å¦å·²ä¿®å¾©**:

```bash
# æŸ¥è©¢è³‡æ–™æ˜¯å¦æœ‰è®Šå‹•
docker exec -i crawler_postgres psql -U stock_user -d stock_analysis -c \
  "SELECT DISTINCT open_price, close_price FROM stock_daily_data WHERE stock_code = '2330' LIMIT 5;"

# çµæœæ‡‰é¡¯ç¤ºå¤šå€‹ä¸åŒå€¼ï¼Œå¦‚ï¼š
# open_price | close_price
# -----------+-------------
#     293.71 |      293.71
#     287.50 |      285.29
#     285.73 |      289.28
```

**å¦‚æœä»æœªä¿®å¾©**:

```bash
# 1. ç¢ºèªä»£ç¢¼å·²æ›´æ–°
docker-compose logs crawler-service | grep "range loop"

# 2. é‡æ–°å»ºç½®æ˜ åƒæª”
cd crawler-service
docker build -f deployments/Dockerfile -t stock-crawler-service:latest .

# 3. é‡å•Ÿæœå‹™
docker-compose down crawler-service
docker-compose up -d crawler-service

# 4. æ¸…ç©ºè³‡æ–™ä¸¦é‡æ–°çˆ¬å–
docker exec -i crawler_postgres psql -U stock_user -d stock_analysis \
  -c "TRUNCATE TABLE stock_daily_data;"

# 5. é‡æ–°çˆ¬å–
curl -X POST "http://localhost:9627/api/v1/stocks/batch-update" \
  -H "Content-Type: application/json" \
  -d '{"symbols": ["2330"]}'

sleep 20

# 6. é©—è­‰çµæœ
docker exec -i crawler_postgres psql -U stock_user -d stock_analysis -c \
  "SELECT open_price, close_price FROM stock_daily_data WHERE stock_code = '2330' LIMIT 10 ORDER BY trade_date;"
```

### Q8: çˆ¬èŸ²è¶…æ™‚

**ç—‡ç‹€**: çˆ¬èŸ²ä»»å‹™ç¶“å¸¸å¤±æ•—ï¼Œæç¤º "timeout" æˆ– "context deadline"

**è§£æ±ºæ–¹æ¡ˆ**:

1. **å¢åŠ è¶…æ™‚æ™‚é–“**
```yaml
# crawler-service/configs/config.yaml
crawler:
  timeout: 60  # å¾ 30 å¢åŠ åˆ° 60 ç§’
```

2. **æ¸›å°‘ä½µç™¼ä»¥é¿å…éè¼‰**
```yaml
crawler:
  max_workers: 10  # å¾ 20 æ¸›å°‘åˆ° 10
```

3. **æª¢æŸ¥ç¶²è·¯é€£ç·š**
```bash
# æ¸¬è©¦é€£ç·šåˆ°åˆ¸å•†ç¶²ç«™
curl -I https://fubon-ebrokerdj.fbs.com.tw

# æª¢æŸ¥ DNS è§£æ
nslookup fubon-ebrokerdj.fbs.com.tw
```

4. **æŸ¥çœ‹çˆ¬èŸ²æ—¥èªŒ**
```bash
docker-compose logs crawler-service | grep -i timeout
```

### Q9: çˆ¬èŸ²è³‡æ–™ä¸å®Œæ•´ï¼ˆå°‘æ–¼ 1440 ç­†ï¼‰

**ç—‡ç‹€**: çˆ¬å–å¾Œåªæœ‰éƒ¨åˆ†è³‡æ–™

**æª¢æŸ¥æ­¥é©Ÿ**:

```bash
# 1. æŸ¥çœ‹è¨˜éŒ„æ•¸
docker exec -i crawler_postgres psql -U stock_user -d stock_analysis -c \
  "SELECT COUNT(*) FROM stock_daily_data WHERE stock_code = '2330';"

# 2. æŸ¥çœ‹æ—¥æœŸç¯„åœ
docker exec -i crawler_postgres psql -U stock_user -d stock_analysis -c \
  "SELECT MIN(trade_date), MAX(trade_date) FROM stock_daily_data WHERE stock_code = '2330';"

# 3. æª¢æŸ¥çˆ¬èŸ²æ—¥èªŒ
docker-compose logs crawler-service | grep "2330"

# 4. å¦‚æœå°‘æ–¼ 1440 ç­†ï¼Œæª¢æŸ¥åˆ¸å•† API å›æ‡‰
# åœ¨çˆ¬èŸ²ä»£ç¢¼ä¸­æ–°å¢ debug log
```

### Q10: çˆ¬èŸ²æŒçºŒå ±å‘Šè³‡æ–™åº«éŒ¯èª¤

**ç—‡ç‹€**: 
```
Error: failed to insert stock data: connection refused
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥è³‡æ–™åº«é€£ç·š**
```bash
docker-compose exec crawler-service \
  nc -zv postgres 5432
```

2. **æª¢æŸ¥çˆ¬èŸ²ç’°å¢ƒè®Šæ•¸**
```bash
docker-compose config | grep -A 5 crawler-service
```

3. **æŸ¥çœ‹çˆ¬èŸ²è©³ç´°æ—¥èªŒ**
```bash
docker-compose logs -f crawler-service --tail=100
```

4. **é‡å•Ÿçˆ¬èŸ²æœå‹™**
```bash
docker-compose restart crawler-service
```

## ğŸ”Œ API ç›¸é—œ

### Q11: API è«‹æ±‚è¿”å› 500 éŒ¯èª¤

**ç—‡ç‹€**: 
```json
{"status": 500, "message": "Internal Server Error"}
```

**è§£æ±ºæ­¥é©Ÿ**:

1. **æŸ¥çœ‹å¾Œç«¯æ—¥èªŒ**
```bash
docker-compose logs backend | grep ERROR | tail -20
```

2. **æª¢æŸ¥è³‡æ–™åº«é€£ç·š**
```bash
curl http://localhost:9000/health
```

3. **æŸ¥çœ‹è©³ç´°æ—¥èªŒ**
```bash
docker-compose logs backend --tail=100
```

4. **é‡å•Ÿå¾Œç«¯æœå‹™**
```bash
docker-compose restart backend
```

### Q12: API å›æ‡‰é²ç·©

**ç—‡ç‹€**: API è«‹æ±‚è€—æ™‚è¶…é 5 ç§’

**å„ªåŒ–å»ºè­°**:

1. **å•Ÿç”¨å¿«å–**
```bash
# æª¢æŸ¥ Redis æ˜¯å¦é‹è¡Œ
docker-compose ps redis

# æ¸¬è©¦ Redis é€£ç·š
docker-compose exec redis redis-cli ping
```

2. **æª¢æŸ¥è³‡æ–™åº«æŸ¥è©¢æ•ˆèƒ½**
```bash
# é€²å…¥è³‡æ–™åº«æª¢æŸ¥ç´¢å¼•
docker-compose exec postgres psql -U stock_user -d stock_analysis

# æª¢æŸ¥ç´¢å¼•
\d+ stock_daily_data

# å¦‚æœç¼ºå°‘ç´¢å¼•ï¼Œå»ºç«‹
CREATE INDEX idx_stock_code_date ON stock_daily_data(stock_code, trade_date);
```

3. **é™åˆ¶å›å‚³ç­†æ•¸**
```bash
# ä½¿ç”¨åˆ†é è€Œéä¸€æ¬¡è¿”å›æ‰€æœ‰è³‡æ–™
curl "http://localhost:9000/api/v1/stocks/2330/history?limit=100&offset=0"
```

### Q13: API èªè­‰å¤±æ•—

**ç—‡ç‹€**: 
```
{"status": 401, "message": "Unauthorized"}
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ API é‡‘é‘°
echo $API_KEY

# ç¢ºèªè«‹æ±‚ä¸­åŒ…å«æ­£ç¢ºçš„èªè­‰é ­
curl -H "Authorization: Bearer $API_KEY" http://localhost:9000/api/v1/stocks
```

## ğŸ§ª æ¸¬è©¦ç›¸é—œ

### Q14: æ¸¬è©¦ç„¡æ³•åŸ·è¡Œ

**ç—‡ç‹€**: `pytest` æˆ– `go test` å‘½ä»¤å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# å¾Œç«¯æ¸¬è©¦
cd backend

# ç¢ºä¿æ¸¬è©¦è³‡æ–™åº«å­˜åœ¨
pytest --setup-show -v

# æª¢æŸ¥æ¸¬è©¦æ—¥èªŒ
pytest -v -s | tail -50

# Go çˆ¬èŸ²æ¸¬è©¦
cd crawler-service
go test -v ./...
```

### Q15: æ¸¬è©¦è³‡æ–™åº«é€£ç·šå¤±æ•—

**ç—‡ç‹€**: æ¸¬è©¦ç„¡æ³•é€£æ¥æ¸¬è©¦è³‡æ–™åº«

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# ç¢ºä¿æ¸¬è©¦è³‡æ–™åº«é…ç½®æ­£ç¢º
cat conftest.py | grep DATABASE

# æ‰‹å‹•å»ºç«‹æ¸¬è©¦è³‡æ–™åº«
docker-compose exec postgres createdb -U stock_user test_stock_analysis

# é‡æ–°åŸ·è¡Œæ¸¬è©¦
pytest -v
```

## ğŸ“ æ—¥èªŒèˆ‡ç›£æ§

### Q16: æ—¥èªŒæ–‡ä»¶å¤ªå¤§

**ç—‡ç‹€**: `/logs` ç›®éŒ„ä½”ç”¨å¤§é‡ç©ºé–“

**æ¸…ç†æ–¹æ¡ˆ**:

```bash
# æŸ¥çœ‹æ—¥èªŒå¤§å°
du -sh logs/*

# åˆªé™¤ 30 å¤©å‰çš„æ—¥èªŒ
find logs -name "*.log" -mtime +30 -delete

# æˆ–å®šæœŸåŸ·è¡Œæ¸…ç†ï¼ˆæ·»åŠ è‡³ crontabï¼‰
0 3 * * * find /home/jarvis/project/idea/stock/logs -name "*.log" -mtime +30 -delete
```

### Q17: ç„¡æ³•æ‰¾åˆ°ç›£æ§åœ–è¡¨

**ç—‡ç‹€**: Prometheus æˆ– Grafana ç„¡æ³•å­˜å–

**æª¢æŸ¥**:

```bash
# ç¢ºèª Prometheus å®¹å™¨é‹è¡Œ
docker-compose ps prometheus

# æª¢æŸ¥ Grafana å®¹å™¨
docker-compose ps grafana

# è¨ªå• Prometheus
curl http://localhost:9090

# è¨ªå• Grafana
curl http://localhost:3000
```

## ğŸ†˜ é€²éšå•é¡Œ

### Q18: æ‡‰ç”¨ç¨‹å¼è¨˜æ†¶é«”æŒçºŒå¢é•·

**ç—‡ç‹€**: æ‡‰ç”¨é‹è¡Œä¸€æ®µæ™‚é–“å¾Œ OOM (Out of Memory)

**è¨ºæ–·**:

```bash
# ç›£æ§å®¹å™¨è¨˜æ†¶é«”ä½¿ç”¨
docker stats

# æŸ¥çœ‹çˆ¬èŸ²è¨˜æ†¶é«”ä½¿ç”¨
docker exec crawler-service ps aux
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. æ¸›å°‘ `max_workers`
2. æ–°å¢è¨˜æ†¶é«”é™åˆ¶è‡³ docker-compose.yml
3. å¯¦æ–½å®šæœŸé‡å•Ÿ

### Q19: è³‡æ–™åŒæ­¥ä¸ä¸€è‡´

**ç—‡ç‹€**: åŒä¸€è‚¡ç¥¨åœ¨ä¸åŒ API å–å¾—çš„è³‡æ–™ä¸ä¸€è‡´

**æª¢æŸ¥**:

```bash
# æ¯”è¼ƒè³‡æ–™åº«èˆ‡å¤–éƒ¨ API è³‡æ–™
curl https://api.example.com/stock/2330 > external.json
curl http://localhost:9000/api/v1/stocks/2330 > internal.json

# æ¯”å°å·®ç•°
diff external.json internal.json
```

## ğŸ“ ç²å–å¹«åŠ©

å¦‚å•é¡Œæœªèƒ½è§£æ±ºï¼Œè«‹æä¾›ä»¥ä¸‹è³‡è¨Šï¼š

1. **è©³ç´°éŒ¯èª¤è¨Šæ¯**
```bash
docker-compose logs --all > logs.txt
```

2. **ç³»çµ±è³‡è¨Š**
```bash
docker --version
docker-compose --version
uname -a
```

3. **é…ç½®è³‡è¨Š**
```bash
docker-compose config
```

4. **ç›¸é—œå‘½ä»¤çš„åŸ·è¡Œçµæœ**

5. **æ™‚é–“ç·š** - å•é¡Œç™¼ç”Ÿçš„æ™‚é–“é»å’Œå‰å¾Œæ“ä½œ

## æ›´å¤šè³‡æº

- [å¿«é€Ÿé–‹å§‹](../guides/QUICK_START.md)
- [ä½¿ç”¨æŒ‡å—](../guides/USAGE_GUIDE.md)
- [çˆ¬èŸ²æœå‹™æŒ‡å—](../crawler/CRAWLER_SERVICE.md)
- [API æ–‡ä»¶](../backend/API_DOCUMENTATION.md)
